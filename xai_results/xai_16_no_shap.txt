==========Processing best model for Logistic Regression==========
--- LR Coefficients (Magnitude on Scaled Features): ---
Feature         | Coefficient  | Direction
Feature 14     : 2.05869 | Positive (+)
Feature 3      : -2.00840 | Negative (-)
Feature 7      : 1.98902 | Positive (+)
Feature 11     : 1.84492 | Positive (+)
Feature 6      : 1.77676 | Positive (+)
Feature 12     : 1.52925 | Positive (+)
Feature 13     : -1.36814 | Negative (-)
Feature 2      : 1.17390 | Positive (+)
Feature 16     : 0.60257 | Positive (+)
Feature 8      : -0.51473 | Negative (-)

--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 12      | 0.10877
Feature 7       | 0.09096
Feature 13      | 0.08328
Feature 14      | 0.06755
Feature 11      | 0.06179
Feature 3       | 0.05862
Feature 6       | 0.05177
Feature 2       | 0.03503
Feature 16      | 0.01489
Feature 9       | 0.00709

==========Processing best model for Multi-layer Perceptron==========
--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 13      | 0.05996
Feature 12      | 0.05937
Feature 7       | 0.04467
Feature 6       | 0.04228
Feature 3       | 0.03685
Feature 16      | 0.02769
Feature 14      | 0.01705
Feature 11      | 0.01526
Feature 5       | 0.01355
Feature 10      | 0.01341

==========Processing best model for Linear SVC==========
--- LSVC Coefficients (Magnitude on Scaled Features): ---
Feature         | Coefficient  | Direction
Feature 14     : 0.55264 | Positive (+)
Feature 3      : -0.54318 | Negative (-)
Feature 7      : 0.52510 | Positive (+)
Feature 11     : 0.52238 | Positive (+)
Feature 6      : 0.47606 | Positive (+)
Feature 12     : 0.41729 | Positive (+)
Feature 13     : -0.34842 | Negative (-)
Feature 2      : 0.31141 | Positive (+)
Feature 16     : 0.18524 | Positive (+)
Feature 9      : -0.12953 | Negative (-)

--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 12      | 0.10636
Feature 7       | 0.08640
Feature 13      | 0.07357
Feature 14      | 0.06615
Feature 11      | 0.06309
Feature 3       | 0.05713
Feature 6       | 0.04934
Feature 2       | 0.03232
Feature 16      | 0.01710
Feature 9       | 0.00637

==========Processing best model for RBF SVC==========
--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 7       | 0.08828
Feature 13      | 0.08423
Feature 12      | 0.07604
Feature 3       | 0.06140
Feature 11      | 0.03683
Feature 14      | 0.03397
Feature 6       | 0.02935
Feature 2       | 0.02181
Feature 10      | 0.01044
Feature 9       | 0.00896

==========Processing best model for Polynomial SVC==========
--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 15      | 0.05813
Feature 13      | 0.05558
Feature 16      | 0.05126
Feature 10      | 0.04572
Feature 14      | 0.03613
Feature 3       | 0.03464
Feature 2       | 0.03143
Feature 6       | 0.02299
Feature 5       | 0.02104
Feature 12      | 0.01776

==========Processing best model for Sigmoid SVC==========
--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 12      | 0.09662
Feature 7       | 0.07904
Feature 11      | 0.06173
Feature 14      | 0.05648
Feature 13      | 0.04961
Feature 3       | 0.04838
Feature 6       | 0.04800
Feature 2       | 0.04282
Feature 16      | 0.03637
Feature 5       | 0.01856

==========Processing best model for Simple Decision Tree==========
--- DT Feature Importance (Gini/Entropy) ---
Feature 3      : 0.27065
Feature 12     : 0.18083
Feature 11     : 0.11524
Feature 14     : 0.11414
Feature 6      : 0.09512
Feature 2      : 0.04855
Feature 10     : 0.03869
Feature 4      : 0.03014
Feature 7      : 0.02776
Feature 13     : 0.02743

--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 12      | 0.15425
Feature 3       | 0.10465
Feature 13      | 0.05568
Feature 7       | 0.03766
Feature 14      | 0.02730
Feature 6       | 0.02669
Feature 11      | 0.02241
Feature 4       | 0.01654
Feature 10      | 0.01570
Feature 2       | 0.00962

==========Processing best model for Random Forest==========
--- RF Feature Importance (Gini/Entropy) ---
Feature 3      : 0.10099
Feature 6      : 0.09444
Feature 13     : 0.08791
Feature 7      : 0.08085
Feature 11     : 0.08081
Feature 12     : 0.07986
Feature 14     : 0.06680
Feature 2      : 0.05542
Feature 16     : 0.05382
Feature 5      : 0.05380

--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 13      | 0.01332
Feature 3       | 0.01261
Feature 7       | 0.01101
Feature 12      | 0.01085
Feature 6       | 0.00595
Feature 14      | 0.00548
Feature 2       | 0.00414
Feature 16      | 0.00347
Feature 11      | 0.00329
Feature 5       | 0.00268

==========Processing best model for Hist Grad Boosting==========
--- Permutation Importance ---
Feature         | Mean Drop in Accuracy  | Std Dev
Feature 3       | 0.02724
Feature 13      | 0.02187
Feature 7       | 0.02123
Feature 6       | 0.01576
Feature 14      | 0.01178
Feature 12      | 0.01101
Feature 10      | 0.00519
Feature 2       | 0.00365
Feature 5       | 0.00359
Feature 11      | 0.00345

